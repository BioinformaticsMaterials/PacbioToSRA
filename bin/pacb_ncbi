#!/usr/bin/env python

import sys
from os.path import realpath, dirname
APP_ROOT_FULLPATH = dirname(dirname(realpath(__file__)))
sys.path.insert(1, APP_ROOT_FULLPATH)

import concurrent
import click
import errno
import logging
import os

from datetime import datetime
from PacbioToSRA.cell_analysis import CellAnalysis
from PacbioToSRA.ncbi.excel_sheet_from_template import ExcelSheetFromTemplate
from PacbioToSRA.ncbi.sra_submission import SraSubmission


# TODO: This should eventually go into a config file
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] [%(levelname)s] [%(processName)s] [%(threadName)s] %(message)s',
    datefmt="%Y-%m-%d %H:%M:%S"
)
logger = logging.getLogger(__name__)


EXCEL_OUTPUT_FILE_FORMAT = 'sra_submission_{}.xlsx'
MIN_THREADS = 2
MAX_THREADS = 100


############################################
# Click functions (for script parameters)
############################################

@click.group()
def cli():
    pass


@cli.command(help='Creates the Excel file that contains the dataset info required by NCBI.')
@click.option('-i', '--input_fofn_file', 'input_fofn_file',
              required=True, type=click.Path(exists=True, readable=True, resolve_path=True),
              help='The input.fofn file. This file contains the dataset directories.')
@click.option('-p', '--bioproject_id', 'bioproject_id',
              required=True, type=click.STRING,
              help='NCBI BioProject ID created on the NCBI website.')
@click.option('-s', '--biosample_id', 'biosample_id',
              required=True, type=click.STRING,
              help='NCBI BioSample ID created on the NCBI website.')
@click.option('-x', '--excel_output_file', 'excel_output_file',
              required=False, type=click.Path(file_okay=True, resolve_path=True),
              help="Name of the output file. Output format is .xslx. Default file name: {}".format(
                      EXCEL_OUTPUT_FILE_FORMAT.format('<date>')
              ))
@click.option('-t', '--num_threads', 'num_threads',
              required=False, type=click.IntRange(MIN_THREADS, MAX_THREADS),
              help='Number of threads to use. This decreases total process time but requires more system resources.' +
              "Range must be between {} and {}".format(MIN_THREADS, MAX_THREADS))
def create_excel_file(input_fofn_file, bioproject_id, biosample_id, excel_output_file, num_threads):
    __func_error_wrapper(
        __do_create_excel_file,
        input_fofn_file, bioproject_id, biosample_id, excel_output_file, num_threads
    )


@cli.command(help='Uploads the datasets in the input.fofn file to NCBI.')
@click.option('-i', '--input_fofn_file', 'input_fofn_file',
              required=True, type=click.Path(exists=True, readable=True, resolve_path=True),
              help='The input.fofn file. This file contains the dataset directories.')
@click.option('-u', '--username', 'username',
              required=True, type=click.STRING,
              help='Username to use to upload data sets to NCBI.')
@click.option('-k', '--ssh_key_file', 'ssh_key_file',
              required=True, type=click.Path(exists=True, readable=True, resolve_path=True),
              help='SSH key  to use to upload data sets to NCBI.')
def upload(input_fofn_file, username, ssh_key_file):
    __func_error_wrapper(
        __do_upload,
        input_fofn_file, username, ssh_key_file
    )


@cli.command(help='Creates the Excel file that contains the dataset info required by NCBI and uplaods them to NCBI.')
@click.option('-i', '--input_fofn_file', 'input_fofn_file',
              required=True, type=click.Path(exists=True, readable=True, resolve_path=True),
              help='The input.fofn file. This file contains the dataset directories.')
@click.option('-p', '--bioproject_id', 'bioproject_id',
              required=True, type=click.STRING,
              help='NCBI BioProject ID created on the NCBI website.')
@click.option('-s', '--biosample_id', 'biosample_id',
              required=True, type=click.STRING,
              help='NCBI BioSample ID created on the NCBI website.')
@click.option('-x', '--excel_output_file', 'excel_output_file',
              required=False, type=click.Path(file_okay=True, resolve_path=True),
              help='Name of the output file. Output format is .xslx. Default file name: sra_submission_<date>.xlsx')
@click.option('-i', '--input_fofn_file', 'input_fofn_file',
              required=True, type=click.Path(exists=True, readable=True, resolve_path=True),
              help='The input.fofn file. This file contains the dataset directories.')
@click.option('-u', '--username', 'username',
              required=True, type=click.STRING,
              help='Username to use to upload data sets to NCBI.')
@click.option('-k', '--ssh_key_file', 'ssh_key_file',
              required=True, type=click.Path(exists=True, readable=True, resolve_path=True),
              help='SSH key to use to upload data sets to NCBI.')
@click.option('-m', '--enable_multiprocess', 'enable_multiprocess',
              is_flag=True,
              help='Enable multiprocess. Will create excel document and upload files in parallel. ' +
                   'This will speed up the entire process but will require more system resources.')
@click.option('-t', '--num_threads', 'num_threads',
              required=False, type=click.IntRange(MIN_THREADS, MAX_THREADS),
              help='Number of threads to use. This decreases total process time but requires more system resources.' +
              "Range must be between {} and {}".format(MIN_THREADS, MAX_THREADS))
def create_excel_file_and_upload(input_fofn_file, bioproject_id, biosample_id, excel_output_file,
                                 username, ssh_key_file, enable_multiprocess, num_threads):
    __func_error_wrapper(
        __do_create_excel_file_and_upload,
        input_fofn_file, bioproject_id, biosample_id, excel_output_file, username, ssh_key_file,
        enable_multiprocess, num_threads
    )


@cli.command(help='Calculates the total size of the data that will be uploaded.')
@click.option('-i', '--input_fofn_file', 'input_fofn_file',
              required=True, type=click.Path(exists=True, readable=True, resolve_path=True),
              help='The input.fofn file. This file contains the dataset directories.')
def calc_upload_size(input_fofn_file):
    __func_error_wrapper(
        __do_calc_upload_size,
        input_fofn_file
    )


###########################################
# Functions to create the excel file
###########################################

def __do_create_excel_file(input_fofn_file, bioproject_id, biosample_id, excel_output_file, num_threads):
    if not excel_output_file:
        excel_output_file = __generate_excel_file_name()

    # os.path.exists checks if file and dir already exist
    if os.path.exists(excel_output_file):
        raise Exception("File/Directory already exist: {}".format(excel_output_file))

    cell_analyses = __generate_cell_analyses_from_fofn(input_fofn_file)

    sr_data_ws_rows = __generate_rows_for_sr_data_worksheet(bioproject_id, biosample_id, cell_analyses)
    files_ws_rows = __generate_rows_for_files_worksheet(cell_analyses, num_threads)

    __create_excel_workbook(excel_output_file, files_ws_rows, sr_data_ws_rows)

    logger.info('Excel document created.')


def __generate_cell_analyses_from_fofn(input_fofn_file):
    dirs = __extract_dirs_from_fofn(input_fofn_file)
    return __generate_cell_analyses(dirs)


def __extract_dirs_from_fofn(input_fofn_file):
    """Extracts all the root directories from the input.fofn file.

    :param  input_fofn_file:    The file that contains the cell analysis result files.
    :type   input_fofn_file:    string
    :return:                    Root directories of the cell analysis results.
    :rtype                      set
    """
    logger.info("Extracting base directory from: {} ....".format(input_fofn_file))
    dirs = set()
    with open(input_fofn_file, 'r') as fp:
        for f in fp:
            # ex: /mnt/data3/vol60/2420308/0001/Analysis_Results/m150325_061829_42142_c100811842550000001823178610081510_s1_p0.1.subreads.fasta
            # want everything before "Analysis_Results"
            d = dirname(dirname(f.strip()))

            if d == '':
                continue

            if not os.path.exists(d):
                raise Exception("Reading input_fofn_file. Directory does not exist: {}".format(d))

            dirs.add(d)

    if not dirs:
        raise Exception('No directories found in input.fofn file.')

    return dirs


def __generate_cell_analyses(dirs):
    """Get cell analys result information from all the directories

    :param  dirs:   Directories
    :type   dirs:   list
    :return:        Objects that hold information for all the cell result directories
    :rtype          list
    """
    analyses = []
    for d in dirs:
        logger.info("Retrieving cell analysis data from: {}".format(d))
        analyses.append(CellAnalysis(d))

    return analyses


def __generate_rows_for_files_worksheet(cell_analyses, num_threads=0):
    """Generates all the rows for the worksheet that contains information on all the files.

    :param  cell_analyses:  List of all cell analysis result info
    :type   cell_analyses:  list
    :return:                List of rows to insert into an excel worksheet
    :rtype                  list
    """
    logger.info('Generating row data for files worksheet...')

    if num_threads > 1:
        return __do_generate_rows_for_files_worksheet_async(cell_analyses, num_threads)
    else:
        return __do_generate_rows_for_files_worksheet(cell_analyses)


def __do_generate_rows_for_files_worksheet(cell_analyses):
    """Generates all the rows for the worksheet that contains information on all the files.

    :param  cell_analyses:  List of all cell analysis result info
    :type   cell_analyses:  list
    :return:                List of rows to insert into an excel worksheet
    :rtype                  list
    """
    total_cell_analyses = len(cell_analyses)
    analysis_count = 0
    rows = []

    for analysis in cell_analyses:
        analysis_count += 1
        files_info = analysis.get_info_for_files()

        rows.extend(__generate_rows(analysis, files_info, analysis_count, total_cell_analyses))

    return rows


def __do_generate_rows_for_files_worksheet_async(cell_analyses, max_threads=0):
    """Generates all the rows for the worksheet that contains information on all the files.

    :param  cell_analyses:  List of all cell analysis result info
    :type   cell_analyses:  list
    :return:                List of rows to insert into an excel worksheet
    :rtype                  list
    """
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_threads) as executor:
        logger.debug("Submitting job to get file info to Thread Pool...")

        futures = {}
        job_total = len(cell_analyses)
        i = 0

        for analysis in cell_analyses:
            i += 1
            logger.debug("    ({}/{}) Submitting {}".format(i, job_total, analysis.root_dir))
            futures[executor.submit(analysis.get_info_for_files)] = analysis

    total_cell_analyses = len(cell_analyses)
    analysis_count = 0
    rows = []

    for future in concurrent.futures.as_completed(futures):
        analysis_count += 1
        analysis = futures[future]
        files_info = future.result()

        rows.extend(__generate_rows(analysis, files_info, analysis_count, total_cell_analyses))

    return rows


def __generate_rows(analysis, files_info, file_count, total_file_count):
    logger.info("    ({}/{}) Generating specific information for all files ({}) in: {}".format(
        file_count, total_file_count, len(files_info), analysis.root_dir
    ))

    sample_name = analysis.get_value_from_xml_path('Sample/Name')
    sample_plateid = analysis.get_value_from_xml_path('Sample/PlateId')

    rows = []
    for f, info in files_info.iteritems():
        rows.append([sample_name, sample_plateid, info['filename'], info['md5sum']])

    return rows


def __generate_rows_for_sr_data_worksheet(bioproject_id, biosample_id, cell_analyses):
    """Generates all the rows for the worksheet that contains sr data.


    :param  bioproject_id:  BioProject ID
    :rtype  bioporject_id:  string
    :param  biosample_id:   BioSample ID
    :rtype  biosample_id:   string
    :param  cell_analyses:  All cell analysis result info
    :type   cell_analyses:  list
    :return:                Rows to insert into an excel worksheet
    :rtype                  list
    """
    logger.info('Generating row data for sr data worksheet...')
    rows = []
    unique_sample_names = set()
    for r in cell_analyses:
        sample_name = r.get_value_from_xml_path('Sample/Name')
        design_desc = r.get_value_from_xml_path('Primary/ConfigFileName').rstrip('.xml')
        if sample_name not in unique_sample_names:
            rows.append([
                bioproject_id,                  # bioproject_accession
                biosample_id,                   # biosample_accession
                sample_name,                    # sample_name
                sample_name,                    # library_ID
                None,                           # title/short description
                None,                           # library_strategy (click for details)
                None,                           # library_source (click for details)
                None,                           # library_selection (click for details)
                None,                           # library_layout
                r.get_platform(),               # platform (click for details)
                r.get_instrument_model(),       # instrument_model
                design_desc,                    # design_description
                None,                           # reference_genome_assembly (or accession)
                None,                           # alignment_software
                None,                           # forward_read_length
                None,                           # reverse_read_length
                r.get_file_type(),              # filetype
                None,                           # filename
                None,                           # MD5_checksum
                None,                           # filetype
                None,                           # filename
                None,                           # MD5_checksum
            ])

        unique_sample_names.add(sample_name)

    return rows


def __create_excel_workbook(output_filename, files_ws_rows, sr_data_ws_rows):
    """Creates the Excel workbook

    :param  output_filename:    Output file name
    :type   output_filename:    string
    :param  files_ws_rows:      Rows of file data
    :type   files_ws_rows:      list
    :param  sr_data_ws_rows:    Rows of SR Data
    :type   sr_data_ws_rows:    list
    """
    logger.info("Creating {}...".format(output_filename))
    wb = ExcelSheetFromTemplate(output_filename)
    logger.info('    Writing to files worksheet...')
    wb.write_to_files_worksheet(files_ws_rows)
    logger.info('    Writing to sra data worksheet...')
    wb.write_to_sr_data_worksheet(sr_data_ws_rows)


###########################################
# Functions to upload to NCBI
###########################################

def __do_upload(input_fofn_file, username, ssh_key_file):
    # exit if ascp command does not exist
    if not SraSubmission(username, ssh_key_file).ascp_cmd_exist():
        raise Exception("Could not find Aspera's ascp command!")

    cell_analyses = __generate_cell_analyses_from_fofn(input_fofn_file)

    # Get all files to upload
    files_only = []
    for analysis in cell_analyses:
        files_only.extend(analysis.get_files())

    logger.info("Submitting files to NCBI...")

    try:
        SraSubmission(username, ssh_key_file).submit_files(files_only)
        logger.info('Upload complete.')
    except:
        logger.error('Upload failure!')
        raise


def __do_calc_upload_size(input_fofn_file):
    cell_analyses = __generate_cell_analyses_from_fofn(input_fofn_file)

    total_size = 0
    total_files = 0
    for analysis in cell_analyses:
        for f in analysis.get_files():
            size = os.path.getsize(f)
            logger.info("{}: {}".format(f, size))
            total_size += size
            total_files += 1

    logger.info("Total number of files: {}".format(total_files))
    logger.info("Total size: {} ({} MB)".format(total_size, round(total_size/(1024*1024.0), 2)))


###########################################
# Functions for whole process
###########################################

def __do_create_excel_file_and_upload(input_fofn_file, bioproject_id, biosample_id, excel_output_file,
                                      username, ssh_key_file, enable_multiprocess, num_threads):

    excel_args = (input_fofn_file, bioproject_id, biosample_id, excel_output_file, num_threads)
    upload_args = (input_fofn_file, username, ssh_key_file)

    if enable_multiprocess:
        # used multiple processes as workaround for multithread problem with Aspera. "ValueError: signal only works in main thread"
        with concurrent.futures.ProcessPoolExecutor() as executor:
            fs = [
                executor.submit(__do_create_excel_file, *excel_args),
                executor.submit(__do_upload, *upload_args),
            ]

        # just to bubble up the exceptions
        for f in concurrent.futures.as_completed(fs):
            f.result()

    else:
        __do_create_excel_file(*excel_args)
        __do_upload(*upload_args)


###########################################
# Misc.
###########################################

def __generate_excel_file_name():
    """ Create an Excel workbook output file name with the current date.

    :return:    Name of Excel file
    :rtype      string
    """
    return EXCEL_OUTPUT_FILE_FORMAT.format(datetime.now().strftime("%Y%m%d%H%M"))


def __func_error_wrapper(func, *args):
    try:
        func(*args)
        logger.info('Complete')
    except Exception as e:
        logger.error(e.message)
        logger.error('An error was encountered!')
        sys.exit(1)


if __name__ == '__main__':
    cli()

